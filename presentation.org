#+options: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline
#+options: author:t broken-links:nil c:nil creator:nil
#+options: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t num:t
#+options: p:nil pri:nil prop:nil stat:t tags:t tasks:t tex:t
#+options: timestamp:t title:t toc:t todo:t |:t
#+title: GRSTAPS presentation
#+date: 2023-02-02 
#+author: John Phillips, Steve Willson
#+email: john@zeus
#+language: en
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 27.0.90 (Org mode 9.3)

#+startup: beamer
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [bigger]
#+OPTIONS: H:2

* GRSTAPs
** Introduction
GRSTAPs stands for Graphically Recursive Simultaneous Task Allocation,
Planning and Scheduling
*** screenshot                                              :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :BEAMER_col: 0.6
    :END:

   #+ATTR_LaTeX: :width 2in
   #+ATTR_LaTeX: :height 2in
   [[file:./fig1.jpeg]]

** Overview
*** Robot team coordination problem formulation
  - What - task planning
  - Who - task allocation
  - When - scheduling
  - How - motion planning
    
*** GRSTAPS takes a holistic view of heterogeneous multi-robot coordination
  - Incentivize compatibility among solutions generated at different
    levels.
  - Incrementally test to see if what we have so far is good at lower
    levels, revising if not.
  - Avoid getting too specific in the task planning -- robot
    allocation is decided later.

** Contributions
- GRSTAPs solves STAP-STC -- Simultaneous Task Allocation and Planning
  with SpatioTemporal Constraints.
*** Agent-agnostic partially ordered planning
  - Determines tasks necessary to reach the goal state without
    committing any agents.
  - Plans only include a set of tasks with ordering constraints, and
    the required task attributes (capabilities which may or may not be provided
    by multiple robots).

*** Interleaved approach
 - Iteratively assigns agents to tasks until the task requirements are
   satisfied.
  
** Prior Work

- Often do not have the capacity to allow robots to undertake joint
  actions, or assume homogeneous robots.
- Often require extensive /a priori/ knowledge about subteams going
  into the task planner, like size.
- Determines tasks necessary to reach the goal state without committing any agents


** Planning

*** Temporal planning
    The input to a temporal planner is the same as other logic-based planners, except
    that actions have durations associated.
   - State of the world ($W$) is represented by literals and fluents
   - Goal is satisfied if each of its literals explicitly appears in the
     state description and each fluent is assigned to a specific value.
   - Initial world state $s_{init}$ and a goal state $G$, the
     planner's job is to find a (in this case) partially ordered
     sequence of tasks to get from $s_{init}$ to $G$.
   - Plans only include a set of tasks with ordering constraints, to
     allow tasks to be executed in parallel.
** Planning cont.
*** Partial-order planning.
The output of a partial-order planner is a /task network/, a graph
where each vertex is a task, and an edge is a dependency
(happens-before) constraint like: $a_i \prec a_j$ -- $a_i$ must occur
before $a_j$. Tasks that can occur in parallel may occur in parallel
branches. The scheduler refines this plan once actual robot
allocations are made and comes up with a more concrete ordering. We
can do this incrementally.
** Planning cont.
*** Partial-order planning cont.
Given the start and goal states and domain, we output:
- Partially ordered plan represented by a directed graph in which each
  vertex represents a task and each edge represents an ordering
  constraint, denoted $\pi$.
  - $\pi = \langle ST, OC, CL \rangle$
  - $ST$ a set of tasks
  - $OC$ ordering constraint between tasks in ST
  - $CL$ causal links between tasks in ST
- In GRSTAPs, we also compute a /desired trait matrix/ $Y_\pi$,
  specifying desired traits for each task.

** Trait-based time-extended task allocation
- Heterogeneous team of N robots that must collectively execute a set of tasks.
- Each robot is defined by its abilities/traits, which are modeled as
  continuous variables encoded by a trait vector.
- Robot trait matrix includes all individual trait vectors.
- Each row corresponds to one robot, each column to a specific trait.

** Trait-based time-extended task allocation cont.
- Each task in task network T may be executed individually or
  collectively as part of a coalition, depending on the trait
  requirements.
- Traits required by an individual task $a_i$ are defined by a task trait
  requirement vector.
- Can model the assignment of agents to tasks by an allocation matrix
  of 1's and 0's, the solution to the problem is an allocation that
  allows tasks to be performed.
- Allocation $A$ must satisfy $Y_\pi$ when $AQ \ge Y_\pi$.
- We try to maximize $AQ$ during search.

** Scheduling
  - Determining when tasks ($a_i$ and $a_j$) begin and end, given the
    plan and allocation.
  - Schedule ($\sigma$) - assignment of start and end times to each
    task in a task network.

   Given a partial plan and task allocation, which each specify
   ordering and mutex constraints on tasks, come up with a schedule of
   which robot is where when, with information from the motion planner
   about how long motions take. We try to minimize the makespan of the
   schedule by prioritizing nodes based on a heuristic function, NSQ.

** Scheduling cont.
- First, satisfy ordering constraints - $a_i$ must take place before
  $a_j$, logically speaking.
- Mutex constraints - $a_i$ must finish before $a_j$ or $a_j$ must
  finish before $a_i$, because of the allocation.
- Wait constraints - task $a_j$ should not start until a certain time
  after $a_i$ completes (required motion from $a_i$ to $a_j$), we get
  this information from the motion planner.
- Infeasibility of any of these three stages results in this node
  being pruned from the task allocation layer's search.
** Putting it together 
*** Figure                                                  :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :BEAMER_col: 0.6
    :END:
   #+ATTR_LaTeX: :width 2.5in
   #+ATTR_LaTeX: :height 2in
   [[file:./tab1.jpeg]]
** Putting it together cont.
*** Figure                                                  :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :BEAMER_col: 0.6
    :END:
   #+ATTR_LaTeX: :width 2.5in
   #+ATTR_LaTeX: :height 2in
   [[file:./tab2.jpeg]]
** Evaluation
GRSTAPs was compared against two other methods that used the same code:
- STAA -- Sequential Task Allocation Anytime -- when something goes
  wrong by the time we hit motion planning, retry allocation.
- STPA -- Sequential Task Planning Anytime -- restart at the task
  planning layer.

In other words, the same code/methods were used, but we retried at
different points in the pipeline.
** Evaluation cont.
*** Figure                                                  :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :BEAMER_col: 0.6
    :END:
    Scalability with number of robots -- GRSTAPs performs better and
    also seems to scale better.
   #+ATTR_LaTeX: :width 2.5in
   #+ATTR_LaTeX: :height 2in
   [[file:./fig9.jpeg]]
** Evaluation cont.
*** Figure                                                  :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :BEAMER_col: 0.6
    :END:
    Scalability with number of goals -- GRSTAPs performs better and
    also seems to scale better.
   #+ATTR_LaTeX: :width 2.5in
   #+ATTR_LaTeX: :height 2in
   [[file:./fig10.jpeg]]
** Evaluation cont.
They also compared GRSTAPs with other temporal planners by
discretizing the problem entirely -- both motion planning and
allocation were discretized and formulated as a discrete problem for
temporal task planners. Obviously, these did not do as well.
*** Figure                                                  :B_ignoreheading:
    :PROPERTIES:
    :BEAMER_env: ignoreheading
    :BEAMER_col: 0.6
    :END:
    Scalability with number of goals -- GRSTAPs performs better and
    also seems to scale better.
   #+ATTR_LaTeX: :width 2.5in
   #+ATTR_LaTeX: :height 2in
   [[file:./fig11.jpeg]]

** Application to TBAM
*** Interleaving layers
Instead of waiting for the bottom layer to inform us that something
isn't possible, each layer should when possible check for feasibility
incrementally in an interleaved way.
*** Think of a plan in terms of capability requirements
GRSTAPs' trait-based allocation approach allows the planner to avoid
getting into specifics about which robots do what when, making this
flexible for heterogeneous robot teams and reducing dimensionality of
the planner's problem.
